import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import warnings

warnings.filterwarnings('ignore')

# Cargar los datos
df = pd.read_csv('Titanic-Dataset.csv')
# Ver las primeras filas del dataset
print(df.head())

# Resumen de las variables
print(df.info())

# Visualizar valores faltantes
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')

# Imputación de valores faltantes
df['Age'].fillna(df['Age'].median(), inplace=True)
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)
df.drop('Cabin', axis=1, inplace=True)

# Codificación de variables categóricas
df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)

# Verificar los cambios
print(df.info())
# Relación entre supervivencia y otras variables
sns.countplot(x='Survived', data=df)
plt.show()


# Distribución de la edad
sns.histplot(df['Age'], kde=True)
plt.show()

# Boxplot de edad y clase de pasajero
sns.boxplot(x='Pclass', y='Age', data=df)
plt.show()
# Definir características y variable objetivo
X = df.drop(['Survived', 'Name', 'Ticket', 'PassengerId'], axis=1)
y = df['Survived']

# Dividir el conjunto de datos
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Crear y entrenar el modelo
tree_model = DecisionTreeClassifier(random_state=42)
tree_model.fit(X_train, y_train)

# Predicciones
y_pred = tree_model.predict(X_test)
# Matriz de confusión
print(confusion_matrix(y_test, y_pred))

# Informe de clasificación
print(classification_report(y_test, y_pred))
# Ver las primeras filas del dataset
print(df.head())

# Resumen de las variables
print(df.info())

# Estadísticas descriptivas
print(df.describe())
# Visualizar valores faltantes
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
plt.show()
# Relación entre supervivencia y otras variables
sns.countplot(x='Survived', data=df)
plt.show()

# Distribución de la edad
sns.histplot(df['Age'], kde=True)
plt.show()

# Boxplot de edad y clase de pasajero
sns.boxplot(x='Pclass', y='Age', data=df)
plt.show()
# Definir características y variable objetivo
X = df.drop(['Survived', 'Name', 'Ticket', 'PassengerId'], axis=1)
y = df['Survived']

# Dividir el conjunto de datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Crear y entrenar el modelo
tree_model = DecisionTreeClassifier(random_state=42)
tree_model.fit(X_train, y_train)

# Realizar predicciones
y_pred = tree_model.predict(X_test)
# Matriz de confusión
print(confusion_matrix(y_test, y_pred))

# Informe de clasificación
print(classification_report(y_test, y_pred))
# Ver las primeras filas del dataset
print(df.head())

# Resumen de las variables
print(df.info())

# Imputación de valores faltantes en 'Age' con la mediana
df['Age'].fillna(df['Age'].median(), inplace=True)

# Imputación de valores faltantes en 'Embarked' con la moda
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)

# Eliminar la columna 'Cabin' debido a muchos valores faltantes
df.drop('Cabin', axis=1, inplace=True)

# Codificar las variables categóricas
df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)

# Verificar los cambios
print(df.info())
# Definir características y variable objetivo
X = df.drop(['Survived', 'Name', 'Ticket', 'PassengerId'], axis=1)
y = df['Survived']
# Dividir el conjunto de datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
# Crear y entrenar el modelo
tree_model = DecisionTreeClassifier(random_state=42)
tree_model.fit(X_train, y_train)

# Obtener la importancia de las características
feature_importances = tree_model.feature_importances_
features = X.columns

# Crear un DataFrame con la importancia de las características
importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})
importance_df = importance_df.sort_values(by='Importance', ascending=False)

# Mostrar la importancia de las características
print(importance_df)
# Seleccionar las características más importantes (por ejemplo, las 5 más importantes)
top_features = importance_df.head(5)['Feature'].tolist()
X_train_top = X_train[top_features]
X_test_top = X_test[top_features]

# Verificar las características seleccionadas
print(X_train_top.head())
# Crear y entrenar el modelo con las características seleccionadas
tree_model_top = DecisionTreeClassifier(random_state=42)
tree_model_top.fit(X_train_top, y_train)

# Realizar predicciones
y_pred_top = tree_model_top.predict(X_test_top)
# Matriz de confusión
print(confusion_matrix(y_test, y_pred_top))

# Informe de clasificación
print(classification_report(y_test, y_pred_top))
# Ver las primeras filas del dataset
print(df.head())

# Resumen de las variables
print(df.info())

# Imputación de valores faltantes en 'Age' con la mediana
df['Age'].fillna(df['Age'].median(), inplace=True)

# Imputación de valores faltantes en 'Embarked' con la moda
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)

# Eliminar la columna 'Cabin' debido a muchos valores faltantes
df.drop('Cabin', axis=1, inplace=True)

# Codificar las variables categóricas
df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)

# Verificar los cambios
print(df.info())
# Definir características y variable objetivo
X = df.drop(['Survived', 'Name', 'Ticket', 'PassengerId'], axis=1)
y = df['Survived']
# Dividir el conjunto de datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Verificar la división
print("Tamaño del conjunto de entrenamiento:", X_train.shape)
print("Tamaño del conjunto de prueba:", X_test.shape)
# Crear y entrenar el modelo
tree_model = DecisionTreeClassifier(random_state=42)
tree_model.fit(X_train, y_train)

# Realizar predicciones en el conjunto de prueba
y_pred = tree_model.predict(X_test)
# Matriz de confusión
print("Matriz de Confusión:\n", confusion_matrix(y_test, y_pred))

# Informe de clasificación
print("Informe de Clasificación:\n", classification_report(y_test, y_pred))
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix
import warnings

warnings.filterwarnings('ignore')

# Cargar los datos
df = pd.read_csv('Titanic-Dataset.csv')

# Exploración inicial y preprocesamiento
df['Age'].fillna(df['Age'].median(), inplace=True)
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)
df.drop('Cabin', axis=1, inplace=True)
df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)

# Definir características y variable objetivo
X = df.drop(['Survived', 'Name', 'Ticket', 'PassengerId'], axis=1)
y = df['Survived']

# Dividir el conjunto de datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir el modelo
tree_model = DecisionTreeClassifier(random_state=42)

# Definir el conjunto de hiperparámetros
param_grid = {
    'criterion': ['gini', 'entropy'],
    'splitter': ['best', 'random'],
    'max_depth': [None, 10, 20, 30, 40, 50],
    'min_samples_split': [2, 10, 20, 30],
    'min_samples_leaf': [1, 2, 4, 10],
    'max_features': [None, 'auto', 'sqrt', 'log2']
}

# Configurar GridSearchCV
grid_search = GridSearchCV(estimator=tree_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)

# Entrenar el modelo
grid_search.fit(X_train, y_train)

# Mejor conjunto de hiperparámetros
print("Mejores hiperparámetros:", grid_search.best_params_)

# Realizar predicciones con el mejor modelo
best_tree_model = grid_search.best_estimator_
y_pred = best_tree_model.predict(X_test)

# Evaluación del modelo
print("Matriz de Confusión:\n", confusion_matrix(y_test, y_pred))
print("Informe de Clasificación:\n", classification_report(y_test, y_pred))
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix
import warnings

warnings.filterwarnings('ignore')

# Cargar los datos
df = pd.read_csv('Titanic-Dataset.csv')

# Exploración inicial y preprocesamiento
df['Age'].fillna(df['Age'].median(), inplace=True)
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)
df.drop('Cabin', axis=1, inplace=True)
df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)

# Definir características y variable objetivo
X = df.drop(['Survived', 'Name', 'Ticket', 'PassengerId'], axis=1)
y = df['Survived']

# Dividir el conjunto de datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir el modelo
tree_model = DecisionTreeClassifier(random_state=42)

# Definir el conjunto de hiperparámetros
param_grid = {
    'criterion': ['gini', 'entropy'],
    'splitter': ['best', 'random'],
    'max_depth': [None, 10, 20, 30, 40, 50],
    'min_samples_split': [2, 10, 20, 30],
    'min_samples_leaf': [1, 2, 4, 10],
    'max_features': [None, 'auto', 'sqrt', 'log2']
}

# Configurar GridSearchCV
grid_search = GridSearchCV(estimator=tree_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)

# Entrenar el modelo
grid_search.fit(X_train, y_train)

# Mejor conjunto de hiperparámetros
print("Mejores hiperparámetros:", grid_search.best_params_)

# Realizar predicciones con el mejor modelo
best_tree_model = grid_search.best_estimator_
y_pred = best_tree_model.predict(X_test)

# Evaluación del modelo
print("Matriz de Confusión:\n", confusion_matrix(y_test, y_pred))
print("Informe de Clasificación:\n", classification_report(y_test, y_pred))
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import warnings

warnings.filterwarnings('ignore')

# Cargar los datos
df = pd.read_csv('Titanic-Dataset.csv')

# Exploración inicial y preprocesamiento
df['Age'].fillna(df['Age'].median(), inplace=True)
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)
df.drop('Cabin', axis=1, inplace=True)
df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)

# Definir características y variable objetivo
X = df.drop(['Survived', 'Name', 'Ticket', 'PassengerId'], axis=1)
y = df['Survived']

# Dividir el conjunto de datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir el modelo
tree_model = DecisionTreeClassifier(random_state=42)

# Definir el conjunto de hiperparámetros
param_grid = {
    'criterion': ['gini', 'entropy'],
    'splitter': ['best', 'random'],
    'max_depth': [None, 10, 20, 30, 40, 50],
    'min_samples_split': [2, 10, 20, 30],
    'min_samples_leaf': [1, 2, 4, 10],
    'max_features': [None, 'auto', 'sqrt', 'log2']
}

# Configurar GridSearchCV
grid_search = GridSearchCV(estimator=tree_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)

# Entrenar el modelo
grid_search.fit(X_train, y_train)

# Mejor conjunto de hiperparámetros
print("Mejores hiperparámetros:", grid_search.best_params_)

# Realizar predicciones con el mejor modelo
best_tree_model = grid_search.best_estimator_
y_pred = best_tree_model.predict(X_test)

# Evaluación del modelo
print("Matriz de Confusión:\n", confusion_matrix(y_test, y_pred))
print("Informe de Clasificación:\n", classification_report(y_test, y_pred))
print("Exactitud:", accuracy_score(y_test, y_pred))
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
import warnings

warnings.filterwarnings('ignore')

# Cargar los datos
df = pd.read_csv('Titanic-Dataset.csv')

# Exploración inicial y preprocesamiento
df['Age'].fillna(df['Age'].median(), inplace=True)
df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)
df.drop('Cabin', axis=1, inplace=True)
df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)

# Definir características y variable objetivo
X = df.drop(['Survived', 'Name', 'Ticket', 'PassengerId'], axis=1)
y = df['Survived']

# Dividir el conjunto de datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir el modelo
tree_model = DecisionTreeClassifier(random_state=42)

# Definir el conjunto de hiperparámetros
param_grid = {
    'criterion': ['gini', 'entropy'],
    'splitter': ['best', 'random'],
    'max_depth': [None, 10, 20, 30, 40, 50],
    'min_samples_split': [2, 10, 20, 30],
    'min_samples_leaf': [1, 2, 4, 10],
    'max_features': [None, 'auto', 'sqrt', 'log2']
}

# Configurar GridSearchCV
grid_search = GridSearchCV(estimator=tree_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)

# Entrenar el modelo
grid_search.fit(X_train, y_train)

# Mejor conjunto de hiperparámetros
print("Mejores hiperparámetros:", grid_search.best_params_)

# Realizar predicciones con el mejor modelo
best_tree_model = grid_search.best_estimator_
y_pred = best_tree_model.predict(X_test)

# Evaluación del modelo
print("Matriz de Confusión:\n", confusion_matrix(y_test, y_pred))
print("Informe de Clasificación:\n", classification_report(y_test, y_pred))
print("Exactitud:", accuracy_score(y_test, y_pred))

# Matriz de confusión
conf_matrix = confusion_matrix(y_test, y_pred)

# Graficar la matriz de confusión
plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['No sobrevivió', 'Sobrevivió'], yticklabels=['No sobrevivió', 'Sobrevivió'])
plt.xlabel('Predicción')
plt.ylabel('Verdadero')
plt.title('Matriz de Confusión')
plt.show()

# Importancia de características
importances = best_tree_model.feature_importances_
feature_names = X.columns
feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values(by='Importance', ascending=False)

# Graficar la importancia de características
plt.figure(figsize=(10, 7))
sns.barplot(x='Importance', y='Feature', data=feature_importance_df)
plt.title('Importancia de Características')
plt.show()

# Visualización del árbol de decisión
plt.figure(figsize=(20, 10))
plot_tree(best_tree_model, feature_names=X.columns, class_names=['No sobrevivió', 'Sobrevivió'], filled=True, rounded=True)
plt.title('Árbol de Decisión')
plt.show()
